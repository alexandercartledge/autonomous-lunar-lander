{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: define fixed‑start env & rule agent\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean, stdev\n",
    "\n",
    "class LunarWrapper(gym.Wrapper):\n",
    "    \"\"\"Annotate info['fuel_used'] = 1 when main engine fires (action==2).\"\"\"\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "        info[\"fuel_used\"] = 1.0 if action == 2 else 0.0\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "def make_rule_env():\n",
    "    \"\"\"\n",
    "    Build the environment pipeline:\n",
    "      1) fixed start (no x shift)\n",
    "      2) fuel tracking\n",
    "    \"\"\"\n",
    "    base = gym.make(\"LunarLander-v3\")\n",
    "    base = LunarWrapper(base)\n",
    "    return base\n",
    "\n",
    "def rule_action(obs):\n",
    "    \"\"\"\n",
    "    Heuristic:\n",
    "      - fight downward speed\n",
    "      - damp horizontal drift\n",
    "      - stabilize tilt\n",
    "    \"\"\"\n",
    "    x, y, x_dot, y_dot, theta, theta_dot, leg1, leg2 = obs\n",
    "\n",
    "    # vertical control\n",
    "    if y_dot < -0.2 or (y < 0.1 and abs(y_dot) > 0.05):\n",
    "        return 2\n",
    "\n",
    "    # horizontal damping\n",
    "    if x_dot > 0.1:\n",
    "        return 1\n",
    "    if x_dot < -0.1:\n",
    "        return 3\n",
    "\n",
    "    # angle stabilization\n",
    "    if theta > 0.05:\n",
    "        return 3\n",
    "    if theta < -0.05:\n",
    "        return 1\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491c222",
   "metadata": {},
   "source": [
    "This cell defines a minimal “rule‑based” agent for LunarLander‑v3. The function rule_action(obs) then implements a simple flight controller:\n",
    "\n",
    "If the craft is descending too fast (or about to bounce), fire the main engine.\n",
    "\n",
    "If it’s drifting horizontally, fire the appropriate side thruster.\n",
    "\n",
    "If it’s leaning, correct the tilt.\n",
    "\n",
    "Otherwise, do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231b76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10000 episodes.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: run 10 000 episodes and collect metrics\n",
    "\n",
    "env = make_rule_env()\n",
    "n_episodes = 10_000\n",
    "\n",
    "rewards = []\n",
    "fuels = []\n",
    "successes = 0\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    total_fuel = 0.0\n",
    "\n",
    "    while not done:\n",
    "        action = rule_action(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        total_fuel += info.get(\"fuel_used\", 0.0)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    fuels.append(total_fuel)\n",
    "    if total_reward >= 200:\n",
    "        successes += 1\n",
    "\n",
    "print(f\"Finished {n_episodes} episodes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdf179",
   "metadata": {},
   "source": [
    "Here I run 10000 episodes of the rule‑based policy in the random‑start environment. For each episode I accumulate:\n",
    "total_reward: the sum of Gym’s step rewards,\n",
    "total_fuel: the number of main‑engine firings,\n",
    "successes: how many episodes achieved ≥ 200 points (the “solved” threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward:    -486.6\n",
      "Mean fuel used: 114.4\n",
      "Success rate:   874/10000 = 9%\n",
      "→ metrics written to 01_rule_based_baseline_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: report & save mean reward, mean fuel, success rate\n",
    "\n",
    "mean_r   = mean(rewards)\n",
    "mean_f   = mean(fuels)\n",
    "succ_pct = successes / n_episodes\n",
    "\n",
    "print(f\"Mean reward:    {mean_r:.1f}\")\n",
    "print(f\"Mean fuel used: {mean_f:.1f}\")\n",
    "print(f\"Success rate:   {successes}/{n_episodes} = {succ_pct:.0%}\")\n",
    "\n",
    "# save to CSV for plotting later\n",
    "df = pd.DataFrame([{\n",
    "    \"experiment\":       \"rule_based_baseline_fixed\",\n",
    "    \"mean_reward\":      mean_r,\n",
    "    \"mean_fuel\":        mean_f,\n",
    "    \"success_rate\":     succ_pct\n",
    "}])\n",
    "df.to_csv(\"01_rule_based_baseline_metrics.csv\", index=False)\n",
    "print(\"→ metrics written to 01_rule_based_baseline_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1116b93",
   "metadata": {},
   "source": [
    "This final cell simply reports the key summary metrics over the 100 episodes:\n",
    "Mean reward shows overall performance.\n",
    "Mean fuel used indicates efficiency.\n",
    "Success rate is the fraction of landings scoring ≥ 200."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ll_env)",
   "language": "python",
   "name": "ll_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
